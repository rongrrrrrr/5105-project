{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. 加载定性与定量数据 ===\n",
    "df_q = pd.read_csv(\"xxx_定量_匹配结果.csv\")  # 替换为你的定量表路径\n",
    "df_ql = pd.read_csv(\"xxx_定性_匹配结果.csv\")  # 替换为你的定性表路径\n",
    "\n",
    "# === 2. 统一关键词小写处理 ===\n",
    "df_q[\"keyword_lower\"] = df_q[\"keyword\"].str.lower().str.strip()\n",
    "df_ql[\"keyword_lower\"] = df_ql[\"keyword\"].str.lower().str.strip()\n",
    "\n",
    "# === 3. 清洗与合并 ===\n",
    "df_q[\"value_clean\"] = pd.to_numeric(df_q[\"value\"].replace('%', '', regex=True), errors=\"coerce\")\n",
    "df_q_clean = df_q.dropna(subset=[\"value_clean\"])[[\"keyword_lower\", \"value_clean\"]]\n",
    "df_q_clean[\"类型\"] = \"定量\"\n",
    "\n",
    "df_ql[\"value_clean\"] = pd.to_numeric(df_ql[\"total_frequency\"], errors=\"coerce\")\n",
    "df_ql_clean = df_ql.dropna(subset=[\"value_clean\"])[[\"keyword_lower\", \"value_clean\"]]\n",
    "df_ql_clean[\"类型\"] = \"定性\"\n",
    "\n",
    "# 定量优先合并\n",
    "quant_keywords = set(df_q_clean[\"keyword_lower\"])\n",
    "df_ql_clean = df_ql_clean[~df_ql_clean[\"keyword_lower\"].isin(quant_keywords)]\n",
    "df_combined = pd.concat([df_q_clean, df_ql_clean], ignore_index=True)\n",
    "\n",
    "# === 4. 计算每个关键词均值 ===\n",
    "df_avg = df_combined.groupby(\"keyword_lower\").agg({\"value_clean\": \"mean\"}).reset_index()\n",
    "df_avg.columns = [\"关键词\", \"值\"]\n",
    "\n",
    "# === 5. 加载 ESG 指标 ===\n",
    "esg = pd.ExcelFile(\"ESG评价体系0322.xlsx\")  # 替换为你的 ESG 参考表格\n",
    "e_list = esg.parse(\"Environment\")[\"Metric\"].dropna().tolist()\n",
    "s_list = esg.parse(\"Social\")[\"Metric\"].dropna().tolist()\n",
    "g_list = esg.parse(\"Governance\")[\"Metric\"].dropna().tolist()\n",
    "\n",
    "# === 6. 匹配函数 ===\n",
    "def fuzzy_match_metric(keywords, targets, threshold=0.4):\n",
    "    matched = []\n",
    "    for kw in keywords:\n",
    "        best_score, best_match = 0, None\n",
    "        for tgt in targets:\n",
    "            score = SequenceMatcher(None, kw.lower(), tgt.lower()).ratio()\n",
    "            if score > best_score:\n",
    "                best_score, best_match = score, tgt\n",
    "        if best_score >= threshold:\n",
    "            matched.append((kw, best_match, best_score))\n",
    "    return matched\n",
    "\n",
    "def build_match_table(matched_list, df_val, category):\n",
    "    val_map = dict(zip(df_val[\"关键词\"].str.lower(), df_val[\"值\"]))\n",
    "    return pd.DataFrame([{\n",
    "        \"ESG类别\": category,\n",
    "        \"匹配关键词\": kw,\n",
    "        \"ESG指标\": mt,\n",
    "        \"匹配关键词值\": val_map.get(kw.lower(), None)\n",
    "    } for kw, mt, _ in matched_list])\n",
    "\n",
    "# === 7. 执行匹配 ===\n",
    "matched_e = fuzzy_match_metric(df_avg[\"关键词\"], e_list)\n",
    "matched_s = fuzzy_match_metric(df_avg[\"关键词\"], s_list)\n",
    "matched_g = fuzzy_match_metric(df_avg[\"关键词\"], g_list)\n",
    "\n",
    "df_e = build_match_table(matched_e, df_avg, \"E\")\n",
    "df_s = build_match_table(matched_s, df_avg, \"S\")\n",
    "df_g = build_match_table(matched_g, df_avg, \"G\")\n",
    "\n",
    "# === 8. 标准化格式（添加强度与理由） ===\n",
    "def standardize(df):\n",
    "    df = df.rename(columns={\"ESG指标\": \"指标\"})\n",
    "    df[\"匹配强度\"] = \"语义匹配\"\n",
    "    df[\"匹配理由\"] = \"基于关键词含义的模糊匹配\"\n",
    "    return df[[\"指标\", \"匹配关键词\", \"匹配强度\", \"匹配理由\", \"匹配关键词值\"]]\n",
    "\n",
    "df_e_std = standardize(df_e)\n",
    "df_s_std = standardize(df_s)\n",
    "df_g_std = standardize(df_g)\n",
    "\n",
    "# === 9. 相同指标均值去重 ===\n",
    "def dedup_by_metric(df):\n",
    "    return df.groupby(\"指标\").agg({\n",
    "        \"匹配关键词值\": \"mean\",\n",
    "        \"匹配关键词\": \"first\",\n",
    "        \"匹配强度\": \"first\",\n",
    "        \"匹配理由\": \"first\"\n",
    "    }).reset_index()[[\"指标\", \"匹配关键词\", \"匹配强度\", \"匹配理由\", \"匹配关键词值\"]]\n",
    "\n",
    "df_e_final = dedup_by_metric(df_e_std)\n",
    "df_s_final = dedup_by_metric(df_s_std)\n",
    "df_g_final = dedup_by_metric(df_g_std)\n",
    "\n",
    "# === 10. 导出结果 ===\n",
    "with pd.ExcelWriter(\"公司名_ESG_匹配带值_标准格式去重均值版.xlsx\") as writer:\n",
    "    df_e_final.to_excel(writer, sheet_name=\"E环境类\", index=False)\n",
    "    df_s_final.to_excel(writer, sheet_name=\"S社会类\", index=False)\n",
    "    df_g_final.to_excel(writer, sheet_name=\"G治理类\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. 指定每个公司的 ESG 文件路径 ===\n",
    "files = {\n",
    "    \"Alcon\": \"Alcon_ESG_匹配带值_标准格式去重均值版.xlsx\",\n",
    "    \"BMS\": \"BMS_ESG_匹配带值_逗号空格分隔_严格匹配版.xlsx\",\n",
    "    \"EliLilly\": \"EliLilly_ESG_匹配带值_标准格式去重均值版.xlsx\",\n",
    "    \"HengRui\": \"HengRui_ESG_匹配带值_标准格式去重均值版.xlsx\"\n",
    "    # 可继续添加公司\n",
    "}\n",
    "\n",
    "# === 2. 提取每家公司 E sheet 中的指标值 ===\n",
    "company_rows = []\n",
    "\n",
    "for company, path in files.items():\n",
    "    df = pd.read_excel(path, sheet_name=\"E环境类\", usecols=[\"指标\", \"匹配关键词值\"])\n",
    "    df_clean = df.dropna(subset=[\"指标\", \"匹配关键词值\"])\n",
    "    company_row = df_clean.set_index(\"指标\")[\"匹配关键词值\"].to_dict()\n",
    "    company_row[\"公司\"] = company\n",
    "    company_rows.append(company_row)\n",
    "\n",
    "# === 3. 构造 DataFrame，\"公司\" 为行，指标为列 ===\n",
    "df_result = pd.DataFrame(company_rows)\n",
    "df_result = df_result.set_index(\"公司\")\n",
    "\n",
    "# === 4. 导出结果 ===\n",
    "df_result.to_excel(\"ESG_环境类_公司为行_指标为列_聚合总表.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
