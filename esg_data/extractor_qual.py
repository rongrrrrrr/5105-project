import pdfplumber
import pandas as pd
import re
from collections import Counter
import openai
import time
import json
import os

# ========== é…ç½® ==========
pdf_path = "../input/your_pdf.pdf"  # â† è®°å¾—è®¾ç½®ä½ çš„ PDF è·¯å¾„
excel_path = "../ESGè¯„ä»·ä½“ç³»0322.xlsx"
output_path = "è¯é¢‘ç»Ÿè®¡_å«è¿‘ä¹‰è¯.csv"
openai.api_key = "YOUR_API_KEY"  # â† è®°å¾—è®¾ç½®ä½ çš„ OpenAI API å¯†é’¥
model = "gpt-4"

# ========== 1. åŠ è½½å®šæ€§å…³é”®è¯ ==========
def load_keywords_with_synonyms(excel_path):
    xls = pd.ExcelFile(excel_path)
    records = []
    sheet_column_map = {
        'Environment': 'NLPæ–¹æ³•',
        'Social': 'ç ”ç©¶æ–¹æ³•',
        'Governance': 'ç ”ç©¶æ–¹æ³•'
    }
    for sheet, col in sheet_column_map.items():
        df = xls.parse(sheet)
        if 'Possible Keywords' in df.columns and col in df.columns:
            for _, row in df.iterrows():
                if pd.notna(row['Possible Keywords']) and str(row[col]).strip() in ['å®šæ€§', 'å®šæ€§/å®šé‡']:
                    for kw in re.split(r',\s*', str(row['Possible Keywords'])):
                        records.append({"keyword": kw.strip(), "type": row[col], "domain": sheet})
    return pd.DataFrame(records)

# ========== 2. æå–å…¨æ–‡æ–‡æœ¬ ==========
def extract_pdf_text(pdf_path):
    all_text = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if text:
                all_text.append(text)
    return "\n".join(all_text)

# ========== 3. ç”Ÿæˆè¿‘ä¹‰è¯æ‰©å±• ==========
def get_synonyms_batch(keywords):
    prompt = f"""
Please provide 3 to 5 common synonyms or semantically similar expressions for each of the following ESG-related keywords. 
Return the result in JSON format with this structure:
[
  {{"keyword": "original", "synonyms": ["syn1", "syn2", ...] }},
  ...
]

Keywords:
{chr(10).join(f"- {kw}" for kw in keywords)}
"""
    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=1500
        )
        content = response.choices[0].message["content"]
        print("GPT è¿”å›å†…å®¹ï¼š", content)  # âœ… æ·»åŠ è¿™ä¸€è¡ŒæŸ¥çœ‹è¿”å›ç»“æœ
        return content
    except Exception as e:
        print("âŒ GPT é”™è¯¯ï¼š", e)
        return "[]"

# ========== 4. ä¸»æµç¨‹ ==========
def run():
    print("ğŸ“˜ è¯»å–å…³é”®è¯...")
    df_keywords = load_keywords_with_synonyms(excel_path)
    keywords = df_keywords['keyword'].unique().tolist()

    print("ğŸ’¬ ç”Ÿæˆè¿‘ä¹‰è¯...")
    synonyms_json = get_synonyms_batch(keywords)

    synonym_map = {}
    try:
        parsed = json.loads(synonyms_json)
        for item in parsed:
            synonym_map[item['keyword']] = [item['keyword']] + item.get('synonyms', [])
    except Exception as e:
        print("âš ï¸ åŒä¹‰è¯è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å…³é”®è¯", e)
        for k in keywords:
            synonym_map[k] = [k]

    print("ğŸ“„ è¯»å– PDF æ–‡æœ¬...")
    text = extract_pdf_text(pdf_path).lower()

    print("ğŸ“Š ç»Ÿè®¡è¯é¢‘...")
    freq_data = []
    for keyword in keywords:
        total_count = 0
        matches = []
        for syn in synonym_map.get(keyword, [keyword]):
            pattern = re.escape(syn.lower())
            count = len(re.findall(pattern, text))
            if count > 0:
                matches.append((syn, count))
                total_count += count
        freq_data.append({
            "keyword": keyword,
            "total_frequency": total_count,
            "matched_synonyms": "; ".join(f"{s} ({c})" for s, c in matches)
        })

    df_out = pd.DataFrame(freq_data)

    match = re.search(r"(\d{4})", pdf_path)
    if match:
        pdf_year = match.group(1)
        print("ğŸ“„ å½“å‰æ–‡ä»¶åï¼š", pdf_path, "â†’ æå–å¹´ä»½ä¸ºï¼š", pdf_year)
    else:
        pdf_year = ""
        print("âš ï¸ æ–‡ä»¶åä¸­æœªæ‰¾åˆ°å¹´ä»½")

    basename = os.path.splitext(os.path.basename(pdf_path))[0]
    output_filename = f"{basename}_å®šæ€§_ç»“æœ.csv"

    df_out.to_csv(output_filename, index=False)
    print(f"\nâœ… æå–å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {output_filename}")

# ========== æ‰§è¡Œ ==========
if __name__ == '__main__':
    run()