import pdfplumber
import pandas as pd
import time
import json
import re
import os
import openai

# ========= 1. è®¾ç½® =========
pdf_path = "../input/your_pdf.pdf"  # PDF æ–‡ä»¶è·¯å¾„
openai.api_key = os.getenv("OPENAI_API_KEY")  # æ›¿æ¢ä¸ºä½ çš„ OpenAI API å¯†é’¥
model = "gpt-3.5-turbo"  # GPT æ¨¡å‹

# ========= 2. æå–è¡¨æ ¼æ–‡æœ¬å— =========
def extract_table_blocks(pdf_path, max_pages=200):
    blocks = []
    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages[:max_pages]):
            tables = page.extract_tables()
            for table in tables:
                text_block = "\n".join(["\t".join(filter(None, row)) for row in table if any(row)])
                if len(text_block.strip()) > 50:
                    blocks.append({"page": i+1, "text": text_block})
    return blocks

# ========= 3. æ„å»º Prompt =========
def build_prompt(table_text):
    prompt = f"""
You are an ESG data assistant. Extract structured quantitative data from the table below.

Instructions:
- Identify ESG-related keywords (e.g. emissions, energy, waste, GHG).
- For each numerical value, return:
  - `keyword` (best matched ESG concept)
  - `value`
  - `unit`
  - `year`
- You must infer the year from the context of the table if it's present (e.g. column header).
- Return only a JSON array with no explanation.

Example output:
[
  {{"keyword": "GHG emissions", "value": 527000, "unit": "metric tons CO2e", "year": "2022"}},
  {{"keyword": "Energy consumption", "value": 7240000, "unit": "MMBtu", "year": "2023"}}
]

Table content:
""" + table_text
    return prompt.strip()

# ========= 4. GPT è°ƒç”¨ =========
def ask_gpt(prompt):
    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a helpful ESG data extraction assistant."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=1000
        )
        content = response.choices[0].message["content"].strip()
        if content.startswith("```json"):
            content = content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        print("âŒ GPT è°ƒç”¨å¤±è´¥ï¼š", e)
        return []

# ========= 5. ä¸»æµç¨‹ =========
def run():
    print("ğŸ“„ æ­£åœ¨ä» PDF ä¸­æå–è¡¨æ ¼æ–‡æœ¬...")
    table_blocks = extract_table_blocks(pdf_path)
    print(f"âœ… å…±æå–è¡¨æ ¼æ®µè½ï¼š{len(table_blocks)} æ®µ")

    all_records = []
    for i, block in enumerate(table_blocks):
        print(f"\nğŸ” å¤„ç†ç¬¬ {i+1} æ®µè¡¨æ ¼ï¼ˆä½äºç¬¬ {block['page']} é¡µï¼‰")
        prompt = build_prompt(block['text'])
        records = ask_gpt(prompt)
        for r in records:
            if isinstance(r, dict):
                r['page'] = block['page']
        all_records.extend(records)
        time.sleep(1)  # é˜²æ­¢è¯·æ±‚è¿‡å¿«

    df = pd.DataFrame(all_records)

    # ä»æ–‡ä»¶åä¸­æå–å¹´ä»½
    match = re.search(r"(\d{4})", pdf_path)
    if match:
        pdf_year = int(match.group(1))
        print("ğŸ“„ å½“å‰æ–‡ä»¶åï¼š", pdf_path, "â†’ æå–å¹´ä»½ä¸ºï¼š", pdf_year)
        df = df[df['year'].astype(str) == str(pdf_year)]
    else:
        print("âš ï¸ æ–‡ä»¶åä¸­æœªæ‰¾åˆ°å¹´ä»½")

    # æå–ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶åéƒ¨åˆ†
    basename = os.path.splitext(os.path.basename(pdf_path))[0]
    output_filename = f"{basename}_å®šé‡_ç»“æœ.csv"

    df.to_csv(output_filename, index=False)
    print(f"\nâœ… æå–å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {output_filename}")

# ========= æ‰§è¡Œ =========
if __name__ == '__main__':
    run()


