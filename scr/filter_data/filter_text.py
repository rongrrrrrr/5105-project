# filter_txt.py

import os
import re
import json
import torch
import logging
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import BertTokenizer, BertForSequenceClassification, pipeline


# ========== æ—¥å¿—è®¾ç½® ==========
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
log_dir = os.path.join(BASE_DIR, "log")
os.makedirs(log_dir, exist_ok=True)
log_file = os.path.join(log_dir, "filter_txt.log")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(log_file, encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def get_result_path(input_file_path):
    """è‡ªåŠ¨æ„å»ºè¾“å‡ºè·¯å¾„ï¼šä¿å­˜åˆ° esg_filtered_txt ä¸‹"""
    file_dir, file_name = os.path.split(input_file_path)
    file_base, file_ext = os.path.splitext(file_name)
    base_dir = os.path.abspath(os.path.join(file_dir, "../esg_filtered_txt"))
    os.makedirs(base_dir, exist_ok=True)
    output_file_path = os.path.join(base_dir, f"{file_base}_filtered{file_ext}")
    return os.path.normpath(output_file_path)


def plot_distribution(results):
    """å¯è§†åŒ–æ¨¡å‹æ‰“åˆ†åˆ†å¸ƒ"""
    scores = [i[0]['score'] for i in results]
    sns.kdeplot(scores)
    plt.xlabel('Confidence Score')
    plt.title('FinBERT-ESG Classification Score Distribution')
    plt.show()


def see_scores(results, threshold):
    """æ‰“å°ä¸åŒç½®ä¿¡åº¦æ¡ä»¶ä¸‹ä¿ç•™çš„å¥å­æ•°é‡"""
    above_t = sum(1 for r in results if r[0]['score'] > threshold and r[0]['label'] != 'None')
    above_t_minus = sum(1 for r in results if r[0]['score'] > threshold - 0.05 and r[0]['label'] != 'None')
    non_none = sum(1 for r in results if r[0]['label'] != 'None')
    logger.info(f"> {threshold:.2f} åˆ†å¥å­æ•°: {above_t}")
    logger.info(f"> {threshold - 0.05:.2f} åˆ†å¥å­æ•°: {above_t_minus}")
    logger.info(f"> æ‰€æœ‰é None å¥å­æ•°: {non_none}")


def filter_txt(input_file_path, threshold=0.9, max_len=510, view=False):
    """
    è¿‡æ»¤æ¸…æ´—åçš„ ESG æ–‡æœ¬æ–‡ä»¶ï¼Œè¾“å‡ºé«˜ç½®ä¿¡åº¦å¥å­
    :param input_file_path: è¾“å…¥ txt æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€å¥ï¼‰
    :param threshold: åˆ†æ•°é˜ˆå€¼ï¼ˆå»ºè®®é»˜è®¤ 0.9ï¼‰
    :param max_len: å¥å­å­—ç¬¦æœ€å¤§é•¿åº¦ï¼ˆé¿å… BERT æŠ¥é”™ï¼‰
    :param view: æ˜¯å¦å¯è§†åŒ–åˆ†æ•°åˆ†å¸ƒ
    """
    try:
        logger.info(f"[ğŸš€] å¼€å§‹å¤„ç†æ–‡ä»¶ï¼š{input_file_path}")
        logger.info(f"[ğŸ“] é˜ˆå€¼è®¾ç½®ä¸º: {threshold}ï¼Œæœ€å¤§é•¿åº¦: {max_len}")

        logger.info("[ğŸ”] åŠ è½½ FinBERT-ESG æ¨¡å‹...")
        model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-esg', num_labels=4)
        tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-esg')
        device = 0 if torch.cuda.is_available() else -1
        nlp = pipeline("text-classification", model=model, tokenizer=tokenizer, device=device)

        output_file_path = get_result_path(input_file_path)
        with open(input_file_path, 'r', encoding='utf-8') as f:
            lines = [line.strip() for line in f.readlines() if line.strip()]
        logger.info(f"[ğŸ“„] è¾“å…¥å¥å­æ•°: {len(lines)}")

        results, too_long = [], []

        for line in lines:
            if len(line) > 512:
                result = nlp(line[:max_len])
                too_long.append(line)
            else:
                result = nlp(line)
            results.append(result)

        if view:
            see_scores(results, threshold)
            plot_distribution(results)
            logger.warning(f"[âš ï¸] è¶…å‡ºæœ€å¤§é•¿åº¦å¥å­æ•°: {len(too_long)}")

        # ç­›é€‰ç¬¦åˆæ¡ä»¶çš„å¥å­
        filtered = [lines[i] for i in range(len(lines))
                    if results[i][0]['label'] != 'None' and results[i][0]['score'] > threshold]

        with open(output_file_path, 'w', encoding='utf-8') as f:
            for line in filtered:
                f.write(line + '\n')

        logger.info(f"[âœ…] ç­›é€‰å®Œæˆï¼šåŸå§‹ {len(lines)} å¥ â†’ ä¿ç•™ {len(filtered)} å¥")
        logger.info(f"[ğŸ“] è¾“å‡ºæ–‡ä»¶ï¼š{output_file_path}")

    except Exception as e:
        logger.error(f"[âŒ] å‘ç”Ÿé”™è¯¯ï¼š{e}")
        raise e
